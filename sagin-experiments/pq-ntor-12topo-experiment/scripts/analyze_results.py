#!/usr/bin/env python3
"""
PQ-NTORæµ‹è¯•ç»“æœåˆ†æè„šæœ¬
è¯»å–æµ‹è¯•ç»“æœJSONï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-11-24
"""

import json
import sys
from pathlib import Path
from datetime import datetime
import statistics

# é…ç½®
SCRIPT_DIR = Path(__file__).parent
RESULTS_DIR = SCRIPT_DIR.parent / "results" / "local_wsl"
OUTPUT_DIR = SCRIPT_DIR.parent / "results" / "analysis"

OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def load_topology_results(topo_id):
    """åŠ è½½å•ä¸ªæ‹“æ‰‘çš„æµ‹è¯•ç»“æœ"""
    result_file = RESULTS_DIR / f"topo{topo_id:02d}_results.json"

    if not result_file.exists():
        return None

    with open(result_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def analyze_single_topology(topo_id):
    """åˆ†æå•ä¸ªæ‹“æ‰‘çš„æµ‹è¯•ç»“æœ"""
    data = load_topology_results(topo_id)

    if not data:
        return None

    test_runs = data.get('test_runs', [])
    if not test_runs:
        return None

    # ç»Ÿè®¡æŒ‡æ ‡
    total_runs = len(test_runs)
    successful_runs = [r for r in test_runs if r.get('success', False)]
    success_count = len(successful_runs)
    success_rate = success_count / total_runs * 100 if total_runs > 0 else 0

    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼ˆä»…æˆåŠŸçš„æµ‹è¯•ï¼‰
    durations = [r['duration'] for r in successful_runs if 'duration' in r]

    analysis = {
        'topology_id': topo_id,
        'topology_name': data.get('topology_name', f'Topo {topo_id}'),
        'total_runs': total_runs,
        'success_count': success_count,
        'success_rate': success_rate,
        'network_params': data.get('config', {}).get('network_simulation', {}).get('aggregate_params', {})
    }

    if durations:
        analysis['duration_stats'] = {
            'mean': statistics.mean(durations),
            'median': statistics.median(durations),
            'stdev': statistics.stdev(durations) if len(durations) > 1 else 0,
            'min': min(durations),
            'max': max(durations)
        }

    # TODO: è§£æPQ-NTORç‰¹æœ‰æŒ‡æ ‡ï¼ˆä»æ—¥å¿—ä¸­ï¼‰
    # analysis['pq_handshake_time_us'] = ...
    # analysis['circuit_build_time_ms'] = ...

    return analysis


def analyze_all_topologies():
    """åˆ†ææ‰€æœ‰æ‹“æ‰‘çš„æµ‹è¯•ç»“æœ"""
    print("=" * 70)
    print("  ğŸ“Š PQ-NTORæµ‹è¯•ç»“æœåˆ†æ")
    print("=" * 70)

    all_analyses = {}

    for topo_id in range(1, 13):
        print(f"\nåˆ†ææ‹“æ‰‘ {topo_id:02d}...")
        analysis = analyze_single_topology(topo_id)

        if analysis:
            all_analyses[topo_id] = analysis
            print(f"  æ‹“æ‰‘åç§°: {analysis['topology_name']}")
            print(f"  æˆåŠŸç‡: {analysis['success_rate']:.1f}% ({analysis['success_count']}/{analysis['total_runs']})")

            if 'duration_stats' in analysis:
                stats = analysis['duration_stats']
                print(f"  å¹³å‡è€—æ—¶: {stats['mean']:.2f}ç§’ (ä¸­ä½æ•°: {stats['median']:.2f}ç§’)")
                print(f"  è€—æ—¶èŒƒå›´: {stats['min']:.2f} - {stats['max']:.2f}ç§’")

            net = analysis['network_params']
            print(f"  ç½‘ç»œå‚æ•°: å»¶è¿Ÿ={net.get('delay_ms')}ms, "
                  f"å¸¦å®½={net.get('bandwidth_mbps')}Mbps, "
                  f"ä¸¢åŒ…ç‡={net.get('loss_percent')}%")
        else:
            print(f"  âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•ç»“æœ")

    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison_report(all_analyses)

    return all_analyses


def generate_comparison_report(all_analyses):
    """ç”Ÿæˆæ‹“æ‰‘å¯¹æ¯”æŠ¥å‘Š"""
    if not all_analyses:
        print("\nâš ï¸  æ²¡æœ‰å¯åˆ†æçš„æ•°æ®")
        return

    print("\n" + "=" * 70)
    print("  ğŸ“ˆ æ‹“æ‰‘å¯¹æ¯”æŠ¥å‘Š")
    print("=" * 70)

    # ç”ŸæˆMarkdownè¡¨æ ¼
    report_file = OUTPUT_DIR / f"comparison_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# PQ-NTOR 12æ‹“æ‰‘å¯¹æ¯”æŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().isoformat()}\n\n")

        f.write("## æµ‹è¯•ç»“æœæ±‡æ€»\n\n")
        f.write("| æ‹“æ‰‘ID | æ‹“æ‰‘åç§° | æˆåŠŸç‡ | å¹³å‡è€—æ—¶(s) | å»¶è¿Ÿ(ms) | å¸¦å®½(Mbps) | ä¸¢åŒ…ç‡(%) |\n")
        f.write("|--------|----------|--------|-------------|----------|------------|----------|\n")

        for topo_id in sorted(all_analyses.keys()):
            analysis = all_analyses[topo_id]
            name = analysis['topology_name']
            success_rate = analysis['success_rate']

            duration_mean = "-"
            if 'duration_stats' in analysis:
                duration_mean = f"{analysis['duration_stats']['mean']:.2f}"

            net = analysis['network_params']
            delay = net.get('delay_ms', '-')
            bw = net.get('bandwidth_mbps', '-')
            loss = net.get('loss_percent', '-')

            f.write(f"| {topo_id:02d} | {name} | {success_rate:.1f}% | {duration_mean} | "
                    f"{delay} | {bw} | {loss} |\n")

        # åˆ†ç»„ç»Ÿè®¡
        f.write("\n## åˆ†ç»„ç»Ÿè®¡\n\n")

        uplink_topos = [a for tid, a in all_analyses.items() if tid <= 6]
        downlink_topos = [a for tid, a in all_analyses.items() if tid > 6]

        if uplink_topos:
            avg_success_uplink = sum(a['success_rate'] for a in uplink_topos) / len(uplink_topos)
            f.write(f"**ä¸Šè¡Œæ‹“æ‰‘ (1-6)**: å¹³å‡æˆåŠŸç‡ {avg_success_uplink:.1f}%\n\n")

        if downlink_topos:
            avg_success_downlink = sum(a['success_rate'] for a in downlink_topos) / len(downlink_topos)
            f.write(f"**ä¸‹è¡Œæ‹“æ‰‘ (7-12)**: å¹³å‡æˆåŠŸç‡ {avg_success_downlink:.1f}%\n\n")

    print(f"\nâœ… å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='åˆ†æPQ-NTORæµ‹è¯•ç»“æœ')
    parser.add_argument('--topo', type=int, metavar='ID',
                        help='åˆ†æå•ä¸ªæ‹“æ‰‘ (1-12)')

    args = parser.parse_args()

    if args.topo:
        # åˆ†æå•ä¸ªæ‹“æ‰‘
        if not (1 <= args.topo <= 12):
            print("âŒ æ‹“æ‰‘IDå¿…é¡»åœ¨1-12ä¹‹é—´")
            sys.exit(1)

        analysis = analyze_single_topology(args.topo)
        if analysis:
            print(json.dumps(analysis, indent=2, ensure_ascii=False))
        else:
            print(f"âŒ æœªæ‰¾åˆ°æ‹“æ‰‘ {args.topo} çš„æµ‹è¯•ç»“æœ")
            sys.exit(1)
    else:
        # åˆ†ææ‰€æœ‰æ‹“æ‰‘
        analyze_all_topologies()


if __name__ == "__main__":
    main()
